{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gensim karateclub ogb "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d_MJwuOQ69D",
        "outputId": "4f44ed40-c082-4c1b-9344-918674881d49"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
            "Requirement already satisfied: karateclub in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.0.2)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from karateclub) (0.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from karateclub) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.15.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (from karateclub) (0.20.8)\n",
            "Requirement already satisfied: networkx<2.7 in /usr/local/lib/python3.7/dist-packages (from karateclub) (2.6.3)\n",
            "Requirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.3.5)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from karateclub) (4.4.2)\n",
            "Requirement already satisfied: pygsp in /usr/local/lib/python3.7/dist-packages (from karateclub) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->karateclub) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->karateclub) (2022.6)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.12.1+cu113)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->karateclub) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->karateclub) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (4.1.1)\n",
            "Requirement already satisfied: Levenshtein==0.20.8 in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->karateclub) (0.20.8)\n",
            "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from Levenshtein==0.20.8->python-Levenshtein->karateclub) (2.13.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/68860621/ogb-dataset-i-can-not-import-pygnodeproppreddataset-from-ogb-nodeproppred\n",
        "# https://stackoverflow.com/questions/67285115/building-wheels-for-torch-sparse-in-colab-takes-forever/73534928#73534928\n",
        "\n",
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyQVvZrn1I9L",
        "outputId": "397c396a-2d58-4e33-94a4-da3e6aca2f89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch-scatter 2.0.9\n",
            "Uninstalling torch-scatter-2.0.9:\n",
            "  Successfully uninstalled torch-scatter-2.0.9\n",
            "Found existing installation: torch-sparse 0.6.15\n",
            "Uninstalling torch-sparse-0.6.15:\n",
            "  Successfully uninstalled torch-sparse-0.6.15\n",
            "Found existing installation: torch-geometric 2.1.0\n",
            "Uninstalling torch-geometric-2.1.0:\n",
            "  Successfully uninstalled torch-geometric-2.1.0\n",
            "Found existing installation: torch-cluster 1.6.0\n",
            "Uninstalling torch-cluster-1.6.0:\n",
            "  Successfully uninstalled torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Using cached https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Using cached https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Using cached https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.4 MB)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-zhmom4od\n",
            "  Running command git clone -q https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-zhmom4od\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.1.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.1.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.1.0) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0-py3-none-any.whl size=755532 sha256=93545d59dde87a31ada21f65222f3ac659ddb66088adc8e37f11caf144974f9f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7gmbgi1l/wheels/85/c9/07/7936efecad79b906348a7e9fb644d914160544efa9aa7f4b2b\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RgAhrVuf9ROe"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict \n",
        "from karateclub import Node2Vec \n",
        "from ogb.nodeproppred import PygNodePropPredDataset \n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.model_selection import train_test_split \n",
        "from torch_geometric.utils import to_networkx\n",
        "from typing import List \n",
        "from tqdm import tqdm \n",
        "from gensim.models import Word2Vec \n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import networkx as nx \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import random \n",
        "import torch \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_probs(G, p, q):\n",
        "    \"\"\"\n",
        "    Computes probablity distribution of neighbouring nodes\n",
        "    graph: input graph \n",
        "    probs: empty dictionary \n",
        "    p: return parameter\n",
        "    q: in-out parameter\n",
        "    \"\"\"\n",
        "    for source_node in G.nodes(): \n",
        "        for current_node in G.neighbors(source_node): \n",
        "            probs_ = [] \n",
        "            for destination in G.neighbors(current_node): \n",
        "                if destination==source_node: \n",
        "                    prob_ = G[current_node][destination].get('weight',1)*(1/p) \n",
        "                elif destination in G.neighbors(source_node): \n",
        "                    prob_ = G[current_node][destination].get('weight',1) \n",
        "                else: \n",
        "                    prob_ = G[current_node][destination].get('weight',1)*(1/q) \n",
        "                probs_.append(prob_)\n",
        "            probs[source_node]['probablities'][current_node] = probs_/np.sum(probs_)\n",
        "    return probs\n"
      ],
      "metadata": {
        "id": "5s5Ls82a-TB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_walks(G, probs, max_walks, walk_len):\n",
        "    \"\"\"\n",
        "    :graph: input graph\n",
        "    :probs: node probablity distribution\n",
        "    :max_walks: maximum number of random walks per node \n",
        "    walk_len: maximum number of nodes in a random walk\n",
        "    \"\"\"\n",
        "    random_walks = [] \n",
        "    nodes_with_no_walks = []\n",
        "    for start_node in G.nodes():\n",
        "        next_node_options = list(G[start_node])\n",
        "        if len(next_node_options)==0:\n",
        "            nodes_with_no_walks.append(start_node)\n",
        "            break \n",
        "        for i in range(max_walks):\n",
        "            current_walk = []\n",
        "            current_walk.append(start_node)\n",
        "            next_node_options = list(G[start_node])\n",
        "            next_node = np.random.choice(next_node_options)\n",
        "            current_walk.append(next_node)\n",
        "            for j in range(walk_len-2):\n",
        "                next_node_options = list(G[current_walk[-1]])\n",
        "                if len(next_node_options)==0:\n",
        "                    break                \n",
        "                probablities = probs[current_walk[-2]]['probablities'][current_walk[-1]]\n",
        "                next_node = np.random.choice(next_node_options, p=probablities) \n",
        "                current_walk.append(next_node)\n",
        "            random_walks.append(current_walk)\n",
        "    random.shuffle(random_walks)\n",
        "    random_walks = [list(map(str,random_walk)) for random_walk in random_walks]\n",
        "    return random_walks, nodes_with_no_walks\n"
      ],
      "metadata": {
        "id": "ZR4JgqrkIDTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def node2vec(random_walks, window_size, dimensions): \n",
        "    \"\"\"\n",
        "    returns word2vec model with given parameters\n",
        "    \"\"\"\n",
        "    model = Word2Vec(sentences=random_walks, vector_size=dimensions, window=window_size) \n",
        "    return model.wv \n"
      ],
      "metadata": {
        "id": "EemBcel4Lx9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = 20 \n",
        "max_nodes = None # select a subset of nodes for large datasets\n",
        "node_sampling_stategy = 'sequential' # ('random', 'sequential')\n",
        "p = 1.0 \n",
        "q = 0.5 \n",
        "random_state = 42 \n",
        "test_size = 0.2 \n",
        "walk_length = 20 \n",
        "walk_number = 10 \n",
        "window_size = 20 "
      ],
      "metadata": {
        "id": "S_WlfOjuSXBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# G = nx.karate_club_graph() \n",
        "dataset = PygNodePropPredDataset('ogbn-arxiv') \n",
        "G = to_networkx(dataset.data, to_undirected=False)\n",
        "\n",
        "if max_nodes is not None:\n",
        "    if node_sampling_stategy=='random':\n",
        "        subset_nodes = random.sample(G.nodes, max_nodes)\n",
        "    else:\n",
        "        subset_nodes = list(G.nodes)[:max_nodes] \n",
        "    G = G.subgraph(subset_nodes) \n",
        "    mapping = {v:w for w,v in enumerate(sorted(G))}\n",
        "    G = nx.relabel_nodes(G, mapping)\n",
        "\n",
        "probs = defaultdict(dict) \n",
        "for node in G.nodes(): \n",
        "    probs[node]['probablities'] = dict() \n",
        "probs = compute_probs(G, p, q) \n",
        "random_walks, nodes_with_no_walks = generate_random_walks(G, probs, walk_number, walk_length) \n",
        "nv_emb = node2vec(random_walks, window_size, dimensions) \n",
        "implemented_embeddings = nv_emb.vectors\n"
      ],
      "metadata": {
        "id": "jPv_gNzGNOzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb62058-128f-4dcd-a7bc-f8c93ab71f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# club_labels = nx.get_node_attributes(G, 'club') \n",
        "# y = np.array(list(club_labels.values()))\n",
        "y = dataset.data['y']\n",
        "\n",
        "nodes_in_vocabulary = nv_emb.key_to_index.keys()\n",
        "y = [int(v) for w,v in enumerate(y) if str(w) in nodes_in_vocabulary]\n",
        "\n",
        "\n",
        "y = y[:int(1e5)]"
      ],
      "metadata": {
        "id": "437kulgYVd3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "implemented_embeddings = implemented_embeddings[:int(1e5)]"
      ],
      "metadata": {
        "id": "5eQVTsGAlY3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(implemented_embeddings, y, random_state=random_state, test_size=test_size) \n",
        "model = LogisticRegression() \n",
        "model.fit(X_train, y_train) \n",
        "y_pred = model.predict(X_test) \n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KXLeroUVa98",
        "outputId": "66e3624d-74a0-4d55-f89a-c400ab3a2bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Node2Vec(walk_length=walk_length, walk_number=walk_number, window_size=window_size, dimensions=dimensions, p=p, q=q) \n",
        "model.fit(G) \n",
        "karateclub_embeddings = model.get_embedding() \n",
        "\n",
        "karateclub_embeddings"
      ],
      "metadata": {
        "id": "3sm89l2WSMPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(karateclub_embeddings, y, random_state=random_state, test_size=test_size) \n",
        "model = LogisticRegression() \n",
        "model.fit(X_train, y_train) \n",
        "y_pred = model.predict(X_test) \n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "NpPiHSycT0Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_diff = karateclub_embeddings - implemented_embeddings\n",
        "embedding_diff_oned = [np.mean(w) for w in embedding_diff]\n",
        "print(np.mean(embedding_diff_oned))\n",
        "print(np.std(embedding_diff_oned))"
      ],
      "metadata": {
        "id": "pAu1FUboXMSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}